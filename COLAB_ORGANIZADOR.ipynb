{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phx8bFD6wDwt"
      },
      "source": [
        "# COLAB/ORGANIZADOR\n",
        "\n",
        "Para funcionar, deve-se ter um arquivo .zip com uma pasta com o nome do evento dentro dele, dentro desta pasta devem estar as imagens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLJK3gB7Fpoy"
      },
      "source": [
        "\n",
        "# Setup and Authentication\n",
        "As células abaixo configuram seu ambiente com funções úteis, além de estabelecer a conexão com a pasta correta do Google Drive.\n",
        "\n",
        "Você terá acesso às funções:\n",
        "1.   list_files_in_shared_folder\n",
        "2.   create_drive_folder\n",
        "3.   upload_file_to_drive\n",
        "4.   upload_folder_to_drive\n",
        "5.   download_file\n",
        "6.   unzip_file\n",
        "7.   delete_file_from_drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TR7gVleIbjn"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKusBm9-2Zh4",
        "outputId": "bef8be8e-126e-419b-a399-445d9f9beb25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.6/108.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "24-12-19 02:44:20 - Directory /root/.deepface has been created\n",
            "24-12-19 02:44:20 - Directory /root/.deepface/weights has been created\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client\n",
        "!pip install --quiet --upgrade google-api-python-client\n",
        "!pip install --quiet opencv-python\n",
        "!pip install --quiet retina-face\n",
        "!pip install --quiet deepface\n",
        "\n",
        "from google.colab import auth\n",
        "import googleapiclient\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from deepface import DeepFace\n",
        "from retinaface import RetinaFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Cj-RCivHF21"
      },
      "outputs": [],
      "source": [
        "# Necessary paths with respective Google Drive IDs (follows this: drive.google.com/drive/u/1/folders/{ID})\n",
        "SHOWFACE_FOLDER = '1iUXrRc9p0CL-xSXXBuPjjQ0xHtL9YimY' # main showface folder\n",
        "ZIPS_FOLDER = '1-pjXAWbWHAzGSBKIIKBmubmZbJKxVVYMM33OpclJdDNgd4cMPA4gnzZzgJTdWwUXIvlfch1x' # zips of sent files\n",
        "PROCESSED_ZIPS_FOLDER = '1EIiWPBJuMbc1feUWrb3R5mwm72Gv4fm9'\n",
        "ALBUMS_FOLDER = '1ra03dT_nthAPFHh_zFeKfgT91_kiU2Cq' # only extracted images on this one\n",
        "ALBUMS_DOCS = '1RcmynInVP3jFfeqd7g8ocq8El1iOg2Qa3VpBGc-_JNY'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFYZHWQ1Ilcc"
      },
      "source": [
        "### Useful functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJWvTM7THler"
      },
      "outputs": [],
      "source": [
        "def list_files_in_shared_folder(folder_id):\n",
        "    query = f\"'{folder_id}' in parents and trashed = false\"\n",
        "    results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
        "    files = results.get('files', [])\n",
        "    if not files:\n",
        "        print(\"No files found in the shared folder.\")\n",
        "    else:\n",
        "        print(\"Files in the shared folder:\")\n",
        "        for file in files:\n",
        "            print(f\"Name: {file['name']}, ID: {file['id']}\")\n",
        "    return files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeE3q2yRKes6"
      },
      "outputs": [],
      "source": [
        "def create_drive_folder(folder_name, parent_folder_id=None):\n",
        "    \"\"\"Create a folder in Google Drive if it doesn't exist.\"\"\"\n",
        "\n",
        "    # Build the query to search for existing folders\n",
        "    query = f\"name='{folder_name}' and mimeType='application/vnd.google-apps.folder'\"\n",
        "    if parent_folder_id:\n",
        "        query += f\" and '{parent_folder_id}' in parents\"\n",
        "\n",
        "    # Search for existing folders\n",
        "    results = drive_service.files().list(q=query, fields=\"files(id)\").execute()\n",
        "    existing_folders = results.get('files', [])\n",
        "\n",
        "    # If a folder with the same name already exists, return its ID\n",
        "    if existing_folders:\n",
        "        folder_id = existing_folders[0]['id']\n",
        "        print(f\"Folder '{folder_name}' already exists with ID: {folder_id}\")\n",
        "        return folder_id\n",
        "\n",
        "    # If the folder doesn't exist, create it\n",
        "    folder_metadata = {\n",
        "        'name': folder_name,\n",
        "        'mimeType': 'application/vnd.google-apps.folder'\n",
        "    }\n",
        "    if parent_folder_id:\n",
        "        folder_metadata['parents'] = [parent_folder_id]\n",
        "\n",
        "    folder = drive_service.files().create(body=folder_metadata, fields='id').execute()\n",
        "    print(f\"Created folder '{folder_name}' with ID: {folder['id']}\")\n",
        "    return folder['id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjWtJejMKr4Y"
      },
      "outputs": [],
      "source": [
        "def upload_file_to_drive(file_path, parent_folder_id):\n",
        "    \"\"\"Upload a file to a specified Google Drive folder.\"\"\"\n",
        "    file_name = os.path.basename(file_path)\n",
        "    file_metadata = {\n",
        "        'name': file_name,\n",
        "        'parents': [parent_folder_id]\n",
        "    }\n",
        "    media = MediaFileUpload(file_path, resumable=True)\n",
        "    uploaded_file = drive_service.files().create(\n",
        "        body=file_metadata,\n",
        "        media_body=media,\n",
        "        fields='id'\n",
        "    ).execute()\n",
        "    # print(f\"Uploaded file '{file_name}' with ID: {uploaded_file['id']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXp4KhAmKtiO"
      },
      "outputs": [],
      "source": [
        "def upload_folder_to_drive(local_folder_path, drive_parent_folder_id):\n",
        "    \"\"\"Recursively upload a local folder to a specified Google Drive folder.\"\"\"\n",
        "    for root, dirs, files in os.walk(local_folder_path):\n",
        "        # Maintain a mapping of local folders to their Drive counterparts\n",
        "        folder_mapping = {local_folder_path: drive_parent_folder_id}\n",
        "\n",
        "        # Traverse directories and create them in Google Drive\n",
        "        for directory in dirs:\n",
        "            local_dir_path = os.path.join(root, directory)\n",
        "            drive_folder_id = create_drive_folder(directory, parent_folder_id=folder_mapping[root])\n",
        "            folder_mapping[local_dir_path] = drive_folder_id\n",
        "\n",
        "        # Traverse files and upload them to Google Drive\n",
        "        print('Uploading files')\n",
        "        for file in tqdm(files):\n",
        "            file_path = os.path.join(root, file)\n",
        "            upload_file_to_drive(file_path, parent_folder_id=folder_mapping[root])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSC9eQNvHlAd"
      },
      "outputs": [],
      "source": [
        "def download_file(file_id, file_name):\n",
        "    \"\"\"Downloads a file from Google Drive by ID.\"\"\"\n",
        "    request = drive_service.files().get_media(fileId=file_id)\n",
        "    file_path = f\"/content/{file_name}\"\n",
        "\n",
        "    with open(file_path, 'wb') as file:\n",
        "        downloader = googleapiclient.http.MediaIoBaseDownload(file, request)\n",
        "        done = False\n",
        "        while not done:\n",
        "            status, done = downloader.next_chunk()\n",
        "            print(f\"Download {int(status.progress() * 100)}% complete.\")\n",
        "\n",
        "    print(f\"File downloaded to {file_path}\")\n",
        "    return file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmUevUIcJuV3"
      },
      "outputs": [],
      "source": [
        "def unzip_file(zip_file_path, extract_to='/content/extracted'):\n",
        "    \"\"\"Unzips a file to the specified folder.\"\"\"\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "         # Get the first part of the paths in the ZIP archive\n",
        "        extracted_items = zip_ref.namelist()\n",
        "        if extracted_items:\n",
        "            extracted_folder_name = os.path.normpath(extracted_items[0]).split(os.sep)[0]\n",
        "\n",
        "    extracted_folder_path = os.path.join(extract_to, extracted_folder_name)\n",
        "    print(f\"File unzipped to {extracted_folder_path}\")\n",
        "    return extracted_folder_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIKRa82lwdCC"
      },
      "outputs": [],
      "source": [
        "def move_file_to_folder(file_id, target_folder_id):\n",
        "    \"\"\"Moves a file to a specified folder in Google Drive.\"\"\"\n",
        "    try:\n",
        "        # Retrieve the current parent folders of the file\n",
        "        file_metadata = drive_service.files().get(fileId=file_id, fields='parents').execute()\n",
        "        current_parents = \",\".join(file_metadata.get('parents', []))\n",
        "\n",
        "        # Update the file's parents to move it to the target folder\n",
        "        drive_service.files().update(\n",
        "            fileId=file_id,\n",
        "            addParents=target_folder_id,\n",
        "            removeParents=current_parents,\n",
        "            fields='id, parents'\n",
        "        ).execute()\n",
        "\n",
        "        print(f\"File {file_id} successfully moved to folder {target_folder_id}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while moving the file: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smoFEYO2QvZ6"
      },
      "outputs": [],
      "source": [
        "def get_files_in_folder(folder_dir): #Scans all files in a colab directory\n",
        "  # Returns list with every filename\n",
        "  scanned_files = []\n",
        "  dir = folder_dir\n",
        "\n",
        "  if os.path.exists(dir):\n",
        "      for root, dirs, files in os.walk(dir):\n",
        "          for file in files:\n",
        "              scanned_files.append(file)\n",
        "  else:\n",
        "      print(\"Directory does not exist\")\n",
        "\n",
        "  return scanned_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3JIXziQQxbj"
      },
      "outputs": [],
      "source": [
        "def create_folder(new_folder_dir):\n",
        "  # Creates folder in colab\n",
        "  folder_dir = new_folder_dir\n",
        "\n",
        "  if not os.path.exists(folder_dir):\n",
        "      os.makedirs(folder_dir)\n",
        "      print(f\"Created directory: {folder_dir}\")\n",
        "  else:\n",
        "      print(f\"Directory already exists: {folder_dir}\")\n",
        "\n",
        "  return folder_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXOeoVTfF5Ou"
      },
      "outputs": [],
      "source": [
        "def get_google_sheet_as_dataframe(file_id):\n",
        "    \"\"\"Download a Google Spreadsheet as CSV and return it as a pandas DataFrame.\"\"\"\n",
        "    try:\n",
        "        # Export the spreadsheet as CSV\n",
        "        request = drive_service.files().export_media(\n",
        "            fileId=file_id,\n",
        "            mimeType='text/csv'\n",
        "        )\n",
        "        # Save the exported CSV to memory\n",
        "        csv_data = request.execute()\n",
        "\n",
        "        # Load the CSV data into a pandas DataFrame\n",
        "        from io import StringIO\n",
        "        table_df = pd.read_csv(StringIO(csv_data.decode('utf-8')))\n",
        "\n",
        "        return table_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing the spreadsheet with ID {file_id}: {e}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lv6s8YFfZeex"
      },
      "outputs": [],
      "source": [
        "def update_google_sheet_from_dataframe(spreadsheet_id, dataframe):\n",
        "    \"\"\"Update a Google Spreadsheet with the contents of a pandas DataFrame, starting at A1.\"\"\"\n",
        "    try:\n",
        "\n",
        "        dataframe = dataframe.fillna(\"\")\n",
        "\n",
        "        # Convert the DataFrame to a list of lists (Google Sheets format)\n",
        "        values = [dataframe.columns.tolist()] + dataframe.values.tolist()\n",
        "\n",
        "        # Create the request body\n",
        "        body = {\n",
        "            \"majorDimension\": \"ROWS\",\n",
        "            \"values\": values\n",
        "        }\n",
        "\n",
        "        # Use the Sheets API to update the entire spreadsheet, starting from A1\n",
        "        sheets_service.spreadsheets().values().update(\n",
        "            spreadsheetId=spreadsheet_id,\n",
        "            range=\"A1\",  # Always starts at the first cell\n",
        "            valueInputOption=\"RAW\",\n",
        "            body=body\n",
        "        ).execute()\n",
        "\n",
        "        print(f\"Spreadsheet {spreadsheet_id} updated successfully.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while updating the spreadsheet with ID {spreadsheet_id}: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V0YIqO7Ifr8"
      },
      "source": [
        "## Authentication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ2JKivSCS4K",
        "outputId": "25763efa-14bc-45a2-94d1-04a9eafa937b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authentication complete!\n"
          ]
        }
      ],
      "source": [
        "# Authenticate with Colab's native method\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Initialize the Drive API\n",
        "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
        "drive_service = build('drive', 'v3')\n",
        "sheets_service = build('sheets', 'v4')\n",
        "print(\"Authentication complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw6twkiiD_VF",
        "outputId": "3ed26736-5a90-4f10-ae7a-961d2bd72a7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in the shared folder:\n",
            "Name: Envio de Álbum - Organizador (respostas), ID: 1RcmynInVP3jFfeqd7g8ocq8El1iOg2Qa3VpBGc-_JNY\n",
            "Name: Envio de Selfie - Usuário (respostas), ID: 1HCVTIHQ0DIQRWyl1vAuW-XU6anK_CqD_GIGGCnkcV6E\n",
            "Name: Envio de Selfie - Usuário, ID: 1BNUjfznWTN6AcPNi2nABAcRUJ08CnNaoacZ-PH6kqzM\n",
            "Name: Albums, ID: 1ra03dT_nthAPFHh_zFeKfgT91_kiU2Cq\n",
            "Name: Colabs, ID: 1HXfpPcdXlm8LUGjPFux0vdaPyrVty2cf\n",
            "Name: Envio de Álbum - Organizador, ID: 18sxdkn-rJBIpV9zsM7VYmrNdp33M3RnCgFfDiImG4ZQ\n",
            "Name: Envio de Selfie - Usuário (File responses), ID: 1TIg8DPiAAzOtyOnRDDkW26F3z0by6iA1X_HskpxuPPMt1jyj76mrrB-2F6sLGSHGr9vTQntU\n",
            "Name: Envio de Álbum (File responses), ID: 1pX9LdtpL9D30jHKcfBX5me8wspIDwwUZmVi2fM0NDxYpVgaG2lRpXLS3rJuLay3jDW2V2mQ8\n",
            "Name: Oscar_Emmy_2023_2024, ID: 1gehG-x3DdolRQKfMzeTJh3zRovBSNltH\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': '1RcmynInVP3jFfeqd7g8ocq8El1iOg2Qa3VpBGc-_JNY',\n",
              "  'name': 'Envio de Álbum - Organizador (respostas)'},\n",
              " {'id': '1HCVTIHQ0DIQRWyl1vAuW-XU6anK_CqD_GIGGCnkcV6E',\n",
              "  'name': 'Envio de Selfie - Usuário (respostas)'},\n",
              " {'id': '1BNUjfznWTN6AcPNi2nABAcRUJ08CnNaoacZ-PH6kqzM',\n",
              "  'name': 'Envio de Selfie - Usuário'},\n",
              " {'id': '1ra03dT_nthAPFHh_zFeKfgT91_kiU2Cq', 'name': 'Albums'},\n",
              " {'id': '1HXfpPcdXlm8LUGjPFux0vdaPyrVty2cf', 'name': 'Colabs'},\n",
              " {'id': '18sxdkn-rJBIpV9zsM7VYmrNdp33M3RnCgFfDiImG4ZQ',\n",
              "  'name': 'Envio de Álbum - Organizador'},\n",
              " {'id': '1TIg8DPiAAzOtyOnRDDkW26F3z0by6iA1X_HskpxuPPMt1jyj76mrrB-2F6sLGSHGr9vTQntU',\n",
              "  'name': 'Envio de Selfie - Usuário (File responses)'},\n",
              " {'id': '1pX9LdtpL9D30jHKcfBX5me8wspIDwwUZmVi2fM0NDxYpVgaG2lRpXLS3rJuLay3jDW2V2mQ8',\n",
              "  'name': 'Envio de Álbum (File responses)'},\n",
              " {'id': '1gehG-x3DdolRQKfMzeTJh3zRovBSNltH', 'name': 'Oscar_Emmy_2023_2024'}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# If everything is correct, should show the shared folder items\n",
        "list_files_in_shared_folder(SHOWFACE_FOLDER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQfop_lazAZA"
      },
      "source": [
        "# Crop faces\n",
        "Esse bloco contém a função responsável por realizar o crop das faces contidas em todas imagens extraídas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3qVjbOWRXOD"
      },
      "outputs": [],
      "source": [
        "def crop_faces(extracted_images_dir, cropped_images_dir):\n",
        "  # script for face cropping\n",
        "\n",
        "  print(\"Initializing face cropping\")\n",
        "\n",
        "  # runs face detection on every image provided\n",
        "  # crops and returns cropped images on new folder\n",
        "\n",
        "  extracted_folder = extracted_images_dir\n",
        "  extracted_filenames = get_files_in_folder(extracted_images_dir)\n",
        "\n",
        "  # backends\n",
        "  backends = [\n",
        "    'opencv',\n",
        "    'ssd',\n",
        "    'dlib',\n",
        "    'mtcnn',\n",
        "    'fastmtcnn',\n",
        "    'retinaface',\n",
        "    'mediapipe',\n",
        "    'yolov8',\n",
        "    'yunet',\n",
        "    'centerface',\n",
        "  ]\n",
        "\n",
        "  # face Alignment (straighten cropped face)\n",
        "  alignment_modes = [True, False]\n",
        "\n",
        "  # defines quantity of extracted images\n",
        "  image_quantity = len(extracted_filenames)\n",
        "\n",
        "  image_base_noextension = None\n",
        "  face_number = None\n",
        "\n",
        "  for image in tqdm(extracted_filenames):\n",
        "\n",
        "    current_image_dir = os.path.join(extracted_folder, image)\n",
        "\n",
        "    current_image_base = os.path.basename(current_image_dir)\n",
        "    image_base_noextension = current_image_base.rsplit('.', 1)[0] # no extension at the end\n",
        "\n",
        "    # searching faces\n",
        "    faces = DeepFace.extract_faces(\n",
        "      img_path = current_image_dir,\n",
        "      detector_backend = backends[5], # retinaface as main backend (idx 5)\n",
        "      align = alignment_modes[1],\n",
        "      enforce_detection = False, # If a face isn't detected in a image, ignores and returns empty (if true, returns error)\n",
        "    )\n",
        "\n",
        "    # read the input image\n",
        "    img = cv2.imread(current_image_dir)\n",
        "\n",
        "    face_number = 1\n",
        "\n",
        "    # draw rectangle around the faces and crop the faces\n",
        "    for face in faces:\n",
        "      # access the 'facial_area' for coords\n",
        "      facial_area = face['facial_area']\n",
        "      x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h'] # coords\n",
        "\n",
        "      #cv2.rectangle(img, (x+w, y+h), (x, y), (255, 255, 255), 1) #commented, draws rectangle, not necessary for functionality\n",
        "\n",
        "      faces_cropped = img[y:y + h, x:x + w]\n",
        "\n",
        "      cv2.imwrite(f'{cropped_images_dir}/{image_base_noextension}@face{str(face_number)}@{str(x)}_{str(y)}_{str(w)}_{str(h)}.jpg', faces_cropped)\n",
        "      face_number += 1\n",
        "\n",
        "  print(f'{cropped_images_dir}/{image_base_noextension}@face{str(face_number)}@{str(x)}_{str(y)}_{str(w)}_{str(h)}.jpg')\n",
        "  print(\"Face Cropping Finalized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYHUNUG3GhjH"
      },
      "source": [
        "# Download and Unzip files - Run Face Cropping\n",
        "Este bloco realiza duas funções:\n",
        "\n",
        "1 - Fazer download dos .zips ainda não processados e separá-los em uma nova pasta com o nome do evento\n",
        "\n",
        "2 - Executa o Script de crop de faces, e realiza upload em uma nova pasta, com o nome do evento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsGWBkq_Ggjh"
      },
      "outputs": [],
      "source": [
        "# Get all unprocessed files\n",
        "answers = get_google_sheet_as_dataframe(ALBUMS_DOCS)\n",
        "filtered_answers = answers[(answers[\"PROCESSADO?\"] == False) & (answers[\"Qual seu nome?\"].notna())] # gets all rows that are \"PROCESSADO?\" = False and Name is not NaN\n",
        "\n",
        "files_to_unzip = []\n",
        "for idx, answer in filtered_answers.iterrows():\n",
        "  files_to_unzip.append({'id': answer[3].split('=')[1], 'event_name': answer[2]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2j5eaTUsneaF",
        "outputId": "b4ef7942-4ef6-4492-caa1-e92a05fc49ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to proccess files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Oscar 2024\n",
            "Download 100% complete.\n",
            "File downloaded to /content/Oscar 2024\n",
            "File unzipped to /content/extracted/2024 Oscars Red Carpet_ All the Best Photos - IMDb\n",
            "File 1CLXzUVCqcbUaVFeZwOcguRSf76UKwfGL successfully moved to folder 1EIiWPBJuMbc1feUWrb3R5mwm72Gv4fm9.\n",
            "Folder 'Oscar 2024' already exists with ID: 1KklcK6wl2NxHj4cdLF_-S_8FyHCUB-9m\n",
            "Folder 'images' already exists with ID: 12w2GlKkWwmqh85FzOTFbs11BIwCO-Bt_\n",
            "Uploading files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/100 [00:01<03:11,  1.93s/it]\u001b[A\n",
            "  2%|▏         | 2/100 [00:03<02:59,  1.83s/it]\u001b[A\n",
            "  3%|▎         | 3/100 [00:05<03:03,  1.89s/it]\u001b[A\n",
            "  4%|▍         | 4/100 [00:07<02:50,  1.78s/it]\u001b[A\n",
            "  5%|▌         | 5/100 [00:09<02:56,  1.86s/it]\u001b[A\n",
            "  6%|▌         | 6/100 [00:10<02:50,  1.81s/it]\u001b[A\n",
            "  7%|▋         | 7/100 [00:13<02:58,  1.92s/it]\u001b[A\n",
            "  8%|▊         | 8/100 [00:14<02:43,  1.78s/it]\u001b[A\n",
            "  9%|▉         | 9/100 [00:17<03:24,  2.25s/it]\u001b[A\n",
            " 10%|█         | 10/100 [00:20<03:27,  2.30s/it]\u001b[A\n",
            " 11%|█         | 11/100 [00:22<03:09,  2.13s/it]\u001b[A\n",
            " 12%|█▏        | 12/100 [00:24<03:05,  2.10s/it]\u001b[A\n",
            " 13%|█▎        | 13/100 [00:25<02:55,  2.01s/it]\u001b[A\n",
            " 14%|█▍        | 14/100 [00:28<03:06,  2.17s/it]\u001b[A\n",
            " 15%|█▌        | 15/100 [00:31<03:28,  2.45s/it]\u001b[A\n",
            " 16%|█▌        | 16/100 [00:35<04:08,  2.96s/it]\u001b[A\n",
            " 17%|█▋        | 17/100 [00:37<03:34,  2.59s/it]\u001b[A\n",
            " 18%|█▊        | 18/100 [00:39<03:18,  2.42s/it]\u001b[A\n",
            " 19%|█▉        | 19/100 [00:41<03:16,  2.43s/it]\u001b[A\n",
            " 20%|██        | 20/100 [00:43<03:03,  2.30s/it]\u001b[A\n",
            " 21%|██        | 21/100 [00:47<03:23,  2.58s/it]\u001b[A\n",
            " 22%|██▏       | 22/100 [00:48<03:00,  2.32s/it]\u001b[A\n",
            " 23%|██▎       | 23/100 [00:50<02:54,  2.27s/it]\u001b[A\n",
            " 24%|██▍       | 24/100 [00:52<02:45,  2.18s/it]\u001b[A\n",
            " 25%|██▌       | 25/100 [00:54<02:30,  2.01s/it]\u001b[A\n",
            " 26%|██▌       | 26/100 [00:57<02:48,  2.27s/it]\u001b[A\n",
            " 27%|██▋       | 27/100 [00:59<02:38,  2.16s/it]\u001b[A\n",
            " 28%|██▊       | 28/100 [01:01<02:30,  2.08s/it]\u001b[A\n",
            " 29%|██▉       | 29/100 [01:03<02:30,  2.12s/it]\u001b[A\n",
            " 30%|███       | 30/100 [01:06<02:45,  2.36s/it]\u001b[A\n",
            " 31%|███       | 31/100 [01:08<02:33,  2.22s/it]\u001b[A\n",
            " 32%|███▏      | 32/100 [01:10<02:27,  2.17s/it]\u001b[A\n",
            " 33%|███▎      | 33/100 [01:12<02:19,  2.09s/it]\u001b[A\n",
            " 34%|███▍      | 34/100 [01:14<02:26,  2.23s/it]\u001b[A\n",
            " 35%|███▌      | 35/100 [01:16<02:23,  2.21s/it]\u001b[A\n",
            " 36%|███▌      | 36/100 [01:19<02:20,  2.19s/it]\u001b[A\n",
            " 37%|███▋      | 37/100 [01:20<02:10,  2.08s/it]\u001b[A\n",
            " 38%|███▊      | 38/100 [01:22<02:06,  2.04s/it]\u001b[A\n",
            " 39%|███▉      | 39/100 [01:25<02:19,  2.28s/it]\u001b[A\n",
            " 40%|████      | 40/100 [01:27<02:10,  2.17s/it]\u001b[A\n",
            " 41%|████      | 41/100 [01:30<02:17,  2.33s/it]\u001b[A\n",
            " 42%|████▏     | 42/100 [01:32<02:07,  2.19s/it]\u001b[A\n",
            " 43%|████▎     | 43/100 [01:34<02:03,  2.16s/it]\u001b[A\n",
            " 44%|████▍     | 44/100 [01:36<01:55,  2.07s/it]\u001b[A\n",
            " 45%|████▌     | 45/100 [01:38<01:53,  2.06s/it]\u001b[A\n",
            " 46%|████▌     | 46/100 [01:39<01:46,  1.97s/it]\u001b[A\n",
            " 47%|████▋     | 47/100 [01:42<01:58,  2.23s/it]\u001b[A\n",
            " 48%|████▊     | 48/100 [01:44<01:52,  2.16s/it]\u001b[A\n",
            " 49%|████▉     | 49/100 [01:46<01:47,  2.11s/it]\u001b[A\n",
            " 50%|█████     | 50/100 [01:48<01:46,  2.12s/it]\u001b[A\n",
            " 51%|█████     | 51/100 [01:50<01:37,  2.00s/it]\u001b[A\n",
            " 52%|█████▏    | 52/100 [01:52<01:36,  2.01s/it]\u001b[A\n",
            " 53%|█████▎    | 53/100 [01:54<01:35,  2.02s/it]\u001b[A\n",
            " 54%|█████▍    | 54/100 [01:56<01:26,  1.88s/it]\u001b[A\n",
            " 55%|█████▌    | 55/100 [01:58<01:25,  1.90s/it]\u001b[A\n",
            " 56%|█████▌    | 56/100 [02:00<01:23,  1.91s/it]\u001b[A\n",
            " 57%|█████▋    | 57/100 [02:02<01:26,  2.00s/it]\u001b[A\n",
            " 58%|█████▊    | 58/100 [02:04<01:22,  1.98s/it]\u001b[A\n",
            " 59%|█████▉    | 59/100 [02:06<01:18,  1.92s/it]\u001b[A\n",
            " 60%|██████    | 60/100 [02:07<01:15,  1.88s/it]\u001b[A\n",
            " 61%|██████    | 61/100 [02:09<01:15,  1.94s/it]\u001b[A\n",
            " 62%|██████▏   | 62/100 [02:12<01:21,  2.14s/it]\u001b[A\n",
            " 63%|██████▎   | 63/100 [02:15<01:25,  2.31s/it]\u001b[A\n",
            " 64%|██████▍   | 64/100 [02:17<01:23,  2.31s/it]\u001b[A\n",
            " 65%|██████▌   | 65/100 [02:19<01:16,  2.18s/it]\u001b[A\n",
            " 66%|██████▌   | 66/100 [02:21<01:11,  2.09s/it]\u001b[A\n",
            " 67%|██████▋   | 67/100 [02:23<01:09,  2.09s/it]\u001b[A\n",
            " 68%|██████▊   | 68/100 [02:26<01:17,  2.43s/it]\u001b[A\n",
            " 69%|██████▉   | 69/100 [02:28<01:11,  2.30s/it]\u001b[A\n",
            " 70%|███████   | 70/100 [02:30<01:06,  2.21s/it]\u001b[A\n",
            " 71%|███████   | 71/100 [02:33<01:08,  2.35s/it]\u001b[A\n",
            " 72%|███████▏  | 72/100 [02:35<01:04,  2.31s/it]\u001b[A\n",
            " 73%|███████▎  | 73/100 [02:37<00:59,  2.20s/it]\u001b[A\n",
            " 74%|███████▍  | 74/100 [02:39<00:52,  2.03s/it]\u001b[A\n",
            " 75%|███████▌  | 75/100 [02:40<00:49,  1.97s/it]\u001b[A\n",
            " 76%|███████▌  | 76/100 [02:42<00:47,  1.98s/it]\u001b[A\n",
            " 77%|███████▋  | 77/100 [02:44<00:44,  1.93s/it]\u001b[A\n",
            " 78%|███████▊  | 78/100 [02:46<00:39,  1.79s/it]\u001b[A\n",
            " 79%|███████▉  | 79/100 [02:47<00:37,  1.80s/it]\u001b[A\n",
            " 80%|████████  | 80/100 [02:49<00:36,  1.81s/it]\u001b[A\n",
            " 81%|████████  | 81/100 [02:52<00:38,  2.05s/it]\u001b[A\n",
            " 82%|████████▏ | 82/100 [02:54<00:37,  2.06s/it]\u001b[A\n",
            " 83%|████████▎ | 83/100 [02:56<00:35,  2.09s/it]\u001b[A\n",
            " 84%|████████▍ | 84/100 [02:58<00:32,  2.02s/it]\u001b[A\n",
            " 85%|████████▌ | 85/100 [03:00<00:31,  2.11s/it]\u001b[A\n",
            " 86%|████████▌ | 86/100 [03:02<00:27,  1.97s/it]\u001b[A\n",
            " 87%|████████▋ | 87/100 [03:04<00:24,  1.91s/it]\u001b[A\n",
            " 88%|████████▊ | 88/100 [03:05<00:22,  1.84s/it]\u001b[A\n",
            " 89%|████████▉ | 89/100 [03:07<00:20,  1.90s/it]\u001b[A\n",
            " 90%|█████████ | 90/100 [03:09<00:18,  1.83s/it]\u001b[A\n",
            " 91%|█████████ | 91/100 [03:11<00:16,  1.83s/it]\u001b[A\n",
            " 92%|█████████▏| 92/100 [03:13<00:14,  1.77s/it]\u001b[A\n",
            " 93%|█████████▎| 93/100 [03:16<00:14,  2.12s/it]\u001b[A\n",
            " 94%|█████████▍| 94/100 [03:17<00:11,  1.99s/it]\u001b[A\n",
            " 95%|█████████▌| 95/100 [03:19<00:09,  1.97s/it]\u001b[A\n",
            " 96%|█████████▌| 96/100 [03:21<00:08,  2.05s/it]\u001b[A\n",
            " 97%|█████████▋| 97/100 [03:23<00:06,  2.01s/it]\u001b[A\n",
            " 98%|█████████▊| 98/100 [03:25<00:03,  1.95s/it]\u001b[A\n",
            " 99%|█████████▉| 99/100 [03:27<00:01,  1.90s/it]\u001b[A\n",
            "100%|██████████| 100/100 [03:29<00:00,  2.09s/it]\n",
            " 50%|█████     | 1/2 [03:39<03:39, 219.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 1CLXzUVCqcbUaVFeZwOcguRSf76UKwfGL successfully moved to folder 1EIiWPBJuMbc1feUWrb3R5mwm72Gv4fm9.\n",
            "Finished processing Oscar 2024\n",
            "\n",
            "Processing Grammy\n",
            "Download 100% complete.\n",
            "File downloaded to /content/Grammy\n",
            "File unzipped to /content/extracted/76th Primetime Emmys Red Carpet_ All the Best Photos - IMDb\n",
            "File 1DjFGbkk8GTs8vNLPKYOW-BQ9SOUgbHvI successfully moved to folder 1EIiWPBJuMbc1feUWrb3R5mwm72Gv4fm9.\n",
            "Folder 'Grammy' already exists with ID: 11rDvTb0X8X_5DTQEQao8BZtXDtSjhKKK\n",
            "Folder 'images' already exists with ID: 1VnHA6M2ZI1WH4UJpRBLyHwZeG9zE_j_f\n",
            "Uploading files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/100 [00:01<03:04,  1.86s/it]\u001b[A\n",
            "  2%|▏         | 2/100 [00:04<03:33,  2.18s/it]\u001b[A\n",
            "  3%|▎         | 3/100 [00:06<03:18,  2.04s/it]\u001b[A\n",
            "  4%|▍         | 4/100 [00:07<02:57,  1.85s/it]\u001b[A\n",
            "  5%|▌         | 5/100 [00:10<03:17,  2.07s/it]\u001b[A\n",
            "  6%|▌         | 6/100 [00:12<03:07,  1.99s/it]\u001b[A\n",
            "  7%|▋         | 7/100 [00:13<02:59,  1.93s/it]\u001b[A\n",
            "  8%|▊         | 8/100 [00:15<02:56,  1.92s/it]\u001b[A\n",
            "  9%|▉         | 9/100 [00:17<02:52,  1.90s/it]\u001b[A\n",
            " 10%|█         | 10/100 [00:19<02:48,  1.87s/it]\u001b[A\n",
            " 11%|█         | 11/100 [00:21<02:45,  1.86s/it]\u001b[A\n",
            " 12%|█▏        | 12/100 [00:23<02:46,  1.89s/it]\u001b[A\n",
            " 13%|█▎        | 13/100 [00:24<02:37,  1.81s/it]\u001b[A\n",
            " 14%|█▍        | 14/100 [00:26<02:46,  1.93s/it]\u001b[A\n",
            " 15%|█▌        | 15/100 [00:28<02:41,  1.90s/it]\u001b[A\n",
            " 16%|█▌        | 16/100 [00:31<02:58,  2.12s/it]\u001b[A\n",
            " 17%|█▋        | 17/100 [00:33<02:54,  2.10s/it]\u001b[A\n",
            " 18%|█▊        | 18/100 [00:35<02:46,  2.03s/it]\u001b[A\n",
            " 19%|█▉        | 19/100 [00:37<02:37,  1.94s/it]\u001b[A\n",
            " 20%|██        | 20/100 [00:38<02:30,  1.89s/it]\u001b[A\n",
            " 21%|██        | 21/100 [00:40<02:29,  1.89s/it]\u001b[A\n",
            " 22%|██▏       | 22/100 [00:42<02:19,  1.78s/it]\u001b[A\n",
            " 23%|██▎       | 23/100 [00:44<02:23,  1.86s/it]\u001b[A\n",
            " 24%|██▍       | 24/100 [00:45<02:14,  1.78s/it]\u001b[A\n",
            " 25%|██▌       | 25/100 [00:48<02:34,  2.06s/it]\u001b[A\n",
            " 26%|██▌       | 26/100 [00:50<02:25,  1.97s/it]\u001b[A\n",
            " 27%|██▋       | 27/100 [00:51<02:15,  1.86s/it]\u001b[A\n",
            " 28%|██▊       | 28/100 [00:53<02:07,  1.78s/it]\u001b[A\n",
            " 29%|██▉       | 29/100 [00:55<02:01,  1.71s/it]\u001b[A\n",
            " 30%|███       | 30/100 [00:57<02:03,  1.77s/it]\u001b[A\n",
            " 31%|███       | 31/100 [00:58<02:02,  1.78s/it]\u001b[A\n",
            " 32%|███▏      | 32/100 [01:01<02:13,  1.96s/it]\u001b[A\n",
            " 33%|███▎      | 33/100 [01:03<02:14,  2.00s/it]\u001b[A\n",
            " 34%|███▍      | 34/100 [01:05<02:07,  1.94s/it]\u001b[A\n",
            " 35%|███▌      | 35/100 [01:06<01:56,  1.79s/it]\u001b[A\n",
            " 36%|███▌      | 36/100 [01:08<01:51,  1.75s/it]\u001b[A\n",
            " 37%|███▋      | 37/100 [01:10<02:02,  1.95s/it]\u001b[A\n",
            " 38%|███▊      | 38/100 [01:12<01:57,  1.90s/it]\u001b[A\n",
            " 39%|███▉      | 39/100 [01:15<02:25,  2.39s/it]\u001b[A\n",
            " 40%|████      | 40/100 [01:17<02:09,  2.16s/it]\u001b[A\n",
            " 41%|████      | 41/100 [01:19<01:56,  1.98s/it]\u001b[A\n",
            " 42%|████▏     | 42/100 [01:21<01:54,  1.98s/it]\u001b[A\n",
            " 43%|████▎     | 43/100 [01:23<01:53,  1.99s/it]\u001b[A\n",
            " 44%|████▍     | 44/100 [01:24<01:47,  1.93s/it]\u001b[A\n",
            " 45%|████▌     | 45/100 [01:26<01:45,  1.91s/it]\u001b[A\n",
            " 46%|████▌     | 46/100 [01:28<01:36,  1.79s/it]\u001b[A\n",
            " 47%|████▋     | 47/100 [01:30<01:34,  1.78s/it]\u001b[A\n",
            " 48%|████▊     | 48/100 [01:32<01:40,  1.93s/it]\u001b[A\n",
            " 49%|████▉     | 49/100 [01:34<01:38,  1.94s/it]\u001b[A\n",
            " 50%|█████     | 50/100 [01:36<01:38,  1.96s/it]\u001b[A\n",
            " 51%|█████     | 51/100 [01:38<01:35,  1.94s/it]\u001b[A\n",
            " 52%|█████▏    | 52/100 [01:40<01:33,  1.95s/it]\u001b[A\n",
            " 53%|█████▎    | 53/100 [01:42<01:32,  1.97s/it]\u001b[A\n",
            " 54%|█████▍    | 54/100 [01:43<01:25,  1.86s/it]\u001b[A\n",
            " 55%|█████▌    | 55/100 [01:45<01:26,  1.92s/it]\u001b[A\n",
            " 56%|█████▌    | 56/100 [01:47<01:23,  1.89s/it]\u001b[A\n",
            " 57%|█████▋    | 57/100 [01:49<01:21,  1.90s/it]\u001b[A\n",
            " 58%|█████▊    | 58/100 [01:51<01:19,  1.89s/it]\u001b[A\n",
            " 59%|█████▉    | 59/100 [01:53<01:17,  1.88s/it]\u001b[A\n",
            " 60%|██████    | 60/100 [01:55<01:18,  1.96s/it]\u001b[A\n",
            " 61%|██████    | 61/100 [01:57<01:17,  1.98s/it]\u001b[A\n",
            " 62%|██████▏   | 62/100 [01:59<01:16,  2.01s/it]\u001b[A\n",
            " 63%|██████▎   | 63/100 [02:01<01:09,  1.88s/it]\u001b[A\n",
            " 64%|██████▍   | 64/100 [02:03<01:08,  1.91s/it]\u001b[A\n",
            " 65%|██████▌   | 65/100 [02:05<01:16,  2.19s/it]\u001b[A\n",
            " 66%|██████▌   | 66/100 [02:07<01:11,  2.10s/it]\u001b[A\n",
            " 67%|██████▋   | 67/100 [02:09<01:07,  2.05s/it]\u001b[A\n",
            " 68%|██████▊   | 68/100 [02:11<01:01,  1.92s/it]\u001b[A\n",
            " 69%|██████▉   | 69/100 [02:13<00:58,  1.88s/it]\u001b[A\n",
            " 70%|███████   | 70/100 [02:14<00:54,  1.81s/it]\u001b[A\n",
            " 71%|███████   | 71/100 [02:17<00:56,  1.95s/it]\u001b[A\n",
            " 72%|███████▏  | 72/100 [02:18<00:53,  1.92s/it]\u001b[A\n",
            " 73%|███████▎  | 73/100 [02:20<00:50,  1.88s/it]\u001b[A\n",
            " 74%|███████▍  | 74/100 [02:22<00:46,  1.81s/it]\u001b[A\n",
            " 75%|███████▌  | 75/100 [02:24<00:45,  1.82s/it]\u001b[A\n",
            " 76%|███████▌  | 76/100 [02:26<00:44,  1.84s/it]\u001b[A\n",
            " 77%|███████▋  | 77/100 [02:28<00:48,  2.13s/it]\u001b[A\n",
            " 78%|███████▊  | 78/100 [02:30<00:44,  2.04s/it]\u001b[A\n",
            " 79%|███████▉  | 79/100 [02:32<00:41,  1.97s/it]\u001b[A\n",
            " 80%|████████  | 80/100 [02:34<00:38,  1.91s/it]\u001b[A\n",
            " 81%|████████  | 81/100 [02:36<00:36,  1.90s/it]\u001b[A\n",
            " 82%|████████▏ | 82/100 [02:38<00:34,  1.93s/it]\u001b[A\n",
            " 83%|████████▎ | 83/100 [02:41<00:37,  2.22s/it]\u001b[A\n",
            " 84%|████████▍ | 84/100 [02:43<00:36,  2.30s/it]\u001b[A\n",
            " 85%|████████▌ | 85/100 [02:45<00:31,  2.10s/it]\u001b[A\n",
            " 86%|████████▌ | 86/100 [02:46<00:27,  2.00s/it]\u001b[A\n",
            " 87%|████████▋ | 87/100 [02:49<00:27,  2.08s/it]\u001b[A\n",
            " 88%|████████▊ | 88/100 [02:50<00:23,  1.97s/it]\u001b[A\n",
            " 89%|████████▉ | 89/100 [02:52<00:21,  1.97s/it]\u001b[A\n",
            " 90%|█████████ | 90/100 [02:54<00:19,  1.95s/it]\u001b[A\n",
            " 91%|█████████ | 91/100 [02:56<00:17,  1.92s/it]\u001b[A\n",
            " 92%|█████████▏| 92/100 [02:58<00:15,  1.98s/it]\u001b[A\n",
            " 93%|█████████▎| 93/100 [03:00<00:13,  1.92s/it]\u001b[A\n",
            " 94%|█████████▍| 94/100 [03:02<00:11,  1.90s/it]\u001b[A\n",
            " 95%|█████████▌| 95/100 [03:04<00:09,  1.85s/it]\u001b[A\n",
            " 96%|█████████▌| 96/100 [03:06<00:07,  1.94s/it]\u001b[A\n",
            " 97%|█████████▋| 97/100 [03:08<00:05,  1.94s/it]\u001b[A\n",
            " 98%|█████████▊| 98/100 [03:10<00:03,  1.89s/it]\u001b[A\n",
            " 99%|█████████▉| 99/100 [03:12<00:01,  1.93s/it]\u001b[A\n",
            "100%|██████████| 100/100 [03:13<00:00,  1.94s/it]\n",
            "100%|██████████| 2/2 [06:58<00:00, 209.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 1DjFGbkk8GTs8vNLPKYOW-BQ9SOUgbHvI successfully moved to folder 1EIiWPBJuMbc1feUWrb3R5mwm72Gv4fm9.\n",
            "Finished processing Grammy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print('Starting to proccess files')\n",
        "for file in tqdm(files_to_unzip):\n",
        "  file_id = file['id']\n",
        "  event_name = file['event_name']\n",
        "\n",
        "  print(f'\\nProcessing {event_name}')\n",
        "\n",
        "  # download file\n",
        "  zip_file_path = download_file(file_id, event_name)\n",
        "  # unzip file\n",
        "  extracted_path = unzip_file(zip_file_path, '/content/extracted')\n",
        "\n",
        "  move_file_to_folder(file_id, PROCESSED_ZIPS_FOLDER) # move .zip to processed folder\n",
        "\n",
        "  #cropped images colab folder creation\n",
        "  cropped_images_path = create_folder('/content/cropped')\n",
        "  # crop images\n",
        "  crop_faces(extracted_path, cropped_images_path)\n",
        "\n",
        "  # create necessary folders\n",
        "  event_folder_id = create_drive_folder(event_name, ALBUMS_FOLDER)\n",
        "  raw_images_folder_id = create_drive_folder('images', event_folder_id)\n",
        "  cropped_images_folder_id = create_drive_folder('cropped', event_folder_id)\n",
        "\n",
        "  # start to upload images (raw and cropped)\n",
        "  upload_folder_to_drive(extracted_path, raw_images_folder_id)\n",
        "  upload_folder_to_drive(cropped_images_path, cropped_images_folder_id)\n",
        "\n",
        "\n",
        "  move_file_to_folder(file_id, PROCESSED_ZIPS_FOLDER)  # move .zip to processed folder\n",
        "  !rm -r '/content/extracted' # delete extracted files in extracted_path\n",
        "  !rm -rf {zip_file_path} # delete downloaded zip file\n",
        "  !rm -rf {cropped_images_path} # delete cropped images\n",
        "\n",
        "  print(f'Finished processing {event_name}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z78eDBKW30K"
      },
      "source": [
        "## Update answers docs\n",
        "Mark .zip's as processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZhbB5blGfEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cb90983-bb17-419d-c141-6127d291e129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spreadsheet 1RcmynInVP3jFfeqd7g8ocq8El1iOg2Qa3VpBGc-_JNY updated successfully.\n"
          ]
        }
      ],
      "source": [
        "for idx, answer in answers.iterrows():\n",
        "  if not isinstance(answer['Qual seu nome?'], float): # checks for NaNs\n",
        "    answers.at[idx, 'PROCESSADO?'] = True\n",
        "\n",
        "update_google_sheet_from_dataframe(ALBUMS_DOCS, answers)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}